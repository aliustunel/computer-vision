{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Multimodal Background Subtraction - Implementation\n",
    "\n",
    "## Necessary Imports and Global Variables\n",
    "\n",
    "Let's start with importing necessary libraries and defining common global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "WIDTH = 240\n",
    "HEIGHT = 0\n",
    "\n",
    "RED = 2\n",
    "GREEN = 1\n",
    "BLUE = 0\n",
    "\n",
    "HUE = 0\n",
    "SATURATION = 1\n",
    "VALUE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Necessary Classes\n",
    "\n",
    "According to paper, we have background model B, which contains background tuples. And those background tuples consist of r,b,g,d values. Where r,g,b are RGB values of pixel and d is the number of pixels Sn(i, j), associated with those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBDTuple:\n",
    "    def __init__(self, red, green, blue, d):\n",
    "        self.red = red\n",
    "        self.green = green\n",
    "        self.blue = blue\n",
    "        self.d = d\n",
    "\n",
    "    # Lately, it is used for rgb hsv conversion to suppress shadows\n",
    "    def getHSV(self):\n",
    "        r, g, b = self.red / 255.0, self.green / 255.0, self.blue / 255.0\n",
    "        mx = max(r, g, b)\n",
    "        mn = min(r, g, b)\n",
    "        df = mx - mn\n",
    "        if mx == mn:\n",
    "            h = 0\n",
    "        elif mx == r:\n",
    "            h = (60 * ((g - b) / df) + 360) % 360\n",
    "        elif mx == g:\n",
    "            h = (60 * ((b - r) / df) + 120) % 360\n",
    "        elif mx == b:\n",
    "            h = (60 * ((r - g) / df) + 240) % 360\n",
    "        if mx == 0:\n",
    "            s = 0\n",
    "        else:\n",
    "            s = df / mx * 100\n",
    "        v = mx * 100\n",
    "        return h, s, v\n",
    "\n",
    "class BackgroundTuple:\n",
    "    def __init__(self, tuples):\n",
    "        self.tuples = tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Some Helper Methods\n",
    "\n",
    "We define two helper methods. One to find maximum of three values. Other is to create Background Model B array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(a, b, c):\n",
    "    if (a >= b) and (a >= b):\n",
    "        largest = a\n",
    "\n",
    "    elif (b >= a) and (b >= a):\n",
    "        largest = b\n",
    "    else:\n",
    "        largest = c\n",
    "\n",
    "    return largest\n",
    "\n",
    "def initB(frame):\n",
    "    # B is the array of BackgroundTuple objects. Which have list of rgbdTuples\n",
    "    B = []\n",
    "    for i in range(len(frame)):\n",
    "        subArr = []\n",
    "        for j in range(len(frame[i])):\n",
    "            t = RGBDTuple(frame[i][j][RED], frame[i][j][GREEN], frame[i][j][BLUE], 1)\n",
    "            backTuple = BackgroundTuple([t])\n",
    "            subArr.append(backTuple)\n",
    "        B.append(subArr)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining RegisterBackground Method\n",
    "\n",
    "In the paper, proposed IMBS algorithm contains two methods. One of them is the RegisterBackground method which clusters the background tuples in background samples Sn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registerBackground(n, frame, B, N, D, A):\n",
    "    \n",
    "    # n -> Sampling number\n",
    "    # frame -> Video frame at time t\n",
    "    # B -> Background Model\n",
    "    # N -> Number of background samples to analyze\n",
    "    # D -> The minimal number D of occurrences to consider a tuple ⟨r,g,b,d ≥ D⟩ as a significant background value\n",
    "    # A -> The association threshold A for assigning a pixel to an existing tuple\n",
    "    \n",
    "    if len(B) < 1:\n",
    "        #If background model is empty, first create it with the helper method\n",
    "        B = initB(frame)\n",
    "        return B\n",
    "\n",
    "    for i in range(len(frame)):\n",
    "        for j in range(len(frame[i])):\n",
    "            # Get RGB values of each pixel\n",
    "            rgbPixel = frame[i][j]\n",
    "            if n == 0:\n",
    "                # If it is first sample simply add the rgbd tuple to list.\n",
    "                t = RGBDTuple(frame[i][j][RED], frame[i][j][GREEN], frame[i][j][BLUE], 1)\n",
    "                B[i][j].tuples.append(t)\n",
    "            elif n == N - 1:\n",
    "                for k in range(len(B[i][j].tuples)):\n",
    "                    if B[i][j].tuples[k].d < D:\n",
    "                        # If number of associated pixels are less then D threshold, remove them from list.\n",
    "                        B[i][j].tuples.pop(k)\n",
    "            else:\n",
    "                for k in range(len(B[i][j].tuples)):\n",
    "                    # Associated pixel RGB value\n",
    "                    rgbdTuple = B[i][j].tuples[k]\n",
    "                    if maximum(abs(rgbPixel[RED] - rgbdTuple.red),\n",
    "                               abs(rgbPixel[GREEN] - rgbdTuple.green),\n",
    "                               abs(rgbPixel[BLUE] - rgbdTuple.blue)) <= A:\n",
    "                        # If the difference between current sample pixel and associated pixel is less than threshold\n",
    "                        # simply update the tuple\n",
    "                        rgbdTuple.red = ((rgbdTuple.red * rgbdTuple.d) + rgbPixel[RED]) / (\n",
    "                                rgbdTuple.d + 1)\n",
    "                        rgbdTuple.green = ((rgbdTuple.green * rgbdTuple.d) + rgbPixel[\n",
    "                            GREEN]) / (rgbdTuple.d + 1)\n",
    "                        rgbdTuple.blue = ((rgbdTuple.blue * rgbdTuple.d) + rgbPixel[\n",
    "                            BLUE]) / (rgbdTuple.d + 1)\n",
    "                        rgbdTuple.d += 1\n",
    "                        break\n",
    "                    else:\n",
    "                        # If it not add the current pixel as a new tuple\n",
    "                        t = RGBDTuple(rgbPixel[RED], rgbPixel[GREEN], rgbPixel[BLUE], 1)\n",
    "                        B[i][j].tuples.append(t)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining GetForeground Method\n",
    "\n",
    "Another essential method of IMBS is 'getForeground', which checks the tuples and decides that the pixel is whether foreground or not. Also the compainon method 'getForegroundVisualFrame' is created, to map value 1 to 255 in foreground mask, in order to show as a white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getForeground(frame, B, A):\n",
    "    \n",
    "    # frame -> Video frame at time t\n",
    "    # B -> Background Model\n",
    "    # A -> The association threshold A for assigning a pixel to an existing tuple\n",
    "    \n",
    "    # Create foreground mask\n",
    "    F = np.full((HEIGHT, WIDTH), 1)\n",
    "    for i in range(len(frame)):\n",
    "        for j in range(len(frame[i])):\n",
    "            # Get RGB values of each pixel\n",
    "            rgbPixel = frame[i][j]\n",
    "            if len(B) > 0 and len(B[i][j].tuples) > 0:\n",
    "                for k in range(len(B[i][j].tuples)):\n",
    "                    # Associated pixel RGB value\n",
    "                    rgbdTuple = B[i][j].tuples[k]\n",
    "                    if maximum(abs(rgbPixel[RED] - rgbdTuple.red),\n",
    "                               abs(rgbPixel[GREEN] - rgbdTuple.green),\n",
    "                               abs(rgbPixel[BLUE] - rgbdTuple.blue)) < A:\n",
    "                        # If the difference between current sample pixel and associated pixel is less than threshold\n",
    "                        # simply mark the pixel as not foreground\n",
    "                        F[i][j] = 0\n",
    "                        break\n",
    "    return F\n",
    "\n",
    "def getForegroundVisualFrame(frame):\n",
    "    for i in range(len(frame)):\n",
    "        for j in range(len(frame[i])):\n",
    "            frame[i][j] *= 255\n",
    "    return np.array(frame, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMBS Method\n",
    "\n",
    "Now, IMBS method can be defined since we have essential methods are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMBS(video):\n",
    "    P = 5  # The sampling period\n",
    "    N = 15 # The number background samples to analyse\n",
    "    D = 2  # The minimal number D of occurrences to consider a tuple ⟨r,g,b,d ≥ D⟩ as a significant background value\n",
    "    A = 5  # The association threshold A for assigning a pixel to an existing tuple\n",
    "    t = 0  # Current time\n",
    "    n = 0  # According to a sampling period P, the current frame I is added to L, thus becoming a background sample Sn, 1 ≤ n ≤ N\n",
    "    ts = 0 # The timestamp of the last processed background sample\n",
    "    B = []\n",
    "\n",
    "    if video.isOpened():\n",
    "        ratio = WIDTH / video.get(3)\n",
    "        global HEIGHT\n",
    "        HEIGHT = math.floor(video.get(4) * ratio)\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        resizedFrame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "\n",
    "        frame = np.array(resizedFrame, dtype='int64')\n",
    "        if t - ts > P:\n",
    "            # During the sampling period, tuples are create or updated\n",
    "            B = registerBackground(n, frame, B, N, D, A)\n",
    "            ts = t\n",
    "            n += 1\n",
    "            if n == N:\n",
    "                n = 0\n",
    "\n",
    "        t += 1\n",
    "        foreground = getForeground(frame, B, A)\n",
    "        visualFrame = getForegroundVisualFrame(foreground)\n",
    "        cv2.imshow(\"Foreground\", visualFrame)\n",
    "\n",
    "        cv2.imshow(\"Image\", resizedFrame)\n",
    "        key = cv2.waitKey(100)\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Improvement: Morphological Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMBS2(video):\n",
    "    P = 5  # The sampling period\n",
    "    N = 15 # The number background samples to analyse\n",
    "    D = 2  # The minimal number D of occurrences to consider a tuple ⟨r,g,b,d ≥ D⟩ as a significant background value\n",
    "    A = 5  # The association threshold A for assigning a pixel to an existing tuple\n",
    "    t = 0  # Current time\n",
    "    n = 0  # According to a sampling period P, the current frame I is added to L, thus becoming a background sample Sn, 1 ≤ n ≤ N\n",
    "    ts = 0 # The timestamp of the last processed background sample\n",
    "    B = []\n",
    "\n",
    "    if video.isOpened():\n",
    "        ratio = WIDTH / video.get(3)\n",
    "        global HEIGHT\n",
    "        HEIGHT = math.floor(video.get(4) * ratio)\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "\n",
    "        resizedFrame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "\n",
    "        frame = np.array(resizedFrame, dtype='int64')\n",
    "        if t - ts > P:\n",
    "            # During the sampling period, tuples are create or updated\n",
    "            B = registerBackground(n, frame, B, N, D, A)\n",
    "            ts = t\n",
    "            n += 1\n",
    "            if n == N:\n",
    "                n = 0\n",
    "\n",
    "        t += 1\n",
    "        foreground = getForeground(frame, B, A)\n",
    "        visualFrame = getForegroundVisualFrame(foreground)\n",
    "        \n",
    "        # MORPHOLOGICAL OPERATORS -----------------------------------------------------------------------------------\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        \n",
    "        cv2.imshow(\"Foreground\", visualFrame)\n",
    "\n",
    "        cv2.imshow(\"Image\", resizedFrame)\n",
    "        key = cv2.waitKey(100)\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Improvement: Gaussian Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMBS3(video):\n",
    "    P = 5  # The sampling period\n",
    "    N = 15 # The number background samples to analyse\n",
    "    D = 2  # The minimal number D of occurrences to consider a tuple ⟨r,g,b,d ≥ D⟩ as a significant background value\n",
    "    A = 5  # The association threshold A for assigning a pixel to an existing tuple\n",
    "    t = 0  # Current time\n",
    "    n = 0  # According to a sampling period P, the current frame I is added to L, thus becoming a background sample Sn, 1 ≤ n ≤ N\n",
    "    ts = 0 # The timestamp of the last processed background sample\n",
    "    B = []\n",
    "\n",
    "    if video.isOpened():\n",
    "        ratio = WIDTH / video.get(3)\n",
    "        global HEIGHT\n",
    "        HEIGHT = math.floor(video.get(4) * ratio)\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "        \n",
    "        # GAUSSIAN FILTER ----------------------------------------------------------------------------------------\n",
    "        frame = cv2.GaussianBlur(frame, (13, 13), 0)\n",
    "\n",
    "        resizedFrame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "\n",
    "        frame = np.array(resizedFrame, dtype='int64')\n",
    "        if t - ts > P:\n",
    "            # During the sampling period, tuples are create or updated\n",
    "            B = registerBackground(n, frame, B, N, D, A)\n",
    "            ts = t\n",
    "            n += 1\n",
    "            if n == N:\n",
    "                n = 0\n",
    "\n",
    "        t += 1\n",
    "        foreground = getForeground(frame, B, A)\n",
    "        visualFrame = getForegroundVisualFrame(foreground)\n",
    "        \n",
    "        # MORPHOLOGICAL OPERATORS -----------------------------------------------------------------------------------\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        \n",
    "        cv2.imshow(\"Foreground\", visualFrame)\n",
    "\n",
    "        cv2.imshow(\"Image\", resizedFrame)\n",
    "        key = cv2.waitKey(100)\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow Suppression\n",
    "\n",
    "Now, let's add the shadow suppression method to get rid off shadows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppressShadows(frame, B):\n",
    "    F = np.full((HEIGHT, WIDTH), 0)\n",
    "    # User defined thresholds\n",
    "    alpha = 0.75\n",
    "    beta = 2.1\n",
    "    ts = 40\n",
    "    th = 60\n",
    "\n",
    "    # Get current hsv frame\n",
    "    hsvFrame = cv2.cvtColor(np.array(frame, dtype=np.uint8), cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    for i in range(len(frame)):\n",
    "        for j in range(len(frame[i])):\n",
    "            count = 0\n",
    "            if len(B) > 0 and len(B[i][j].tuples) > 0:\n",
    "                for k in range(len(B[i][j].tuples)):\n",
    "                    rgbd = B[i][j].tuples[k]\n",
    "                    hsvPixel = hsvFrame[i][j]\n",
    "                    h, s, v = rgbd.getHSV()\n",
    "\n",
    "                    if hsvPixel[HUE] - h <= th and hsvPixel[SATURATION] - s <= ts and hsvPixel[VALUE] / v >= alpha and hsvPixel[VALUE] / v <= beta:\n",
    "                        # Check the defined conditions in paper, if it is satisfied increase count\n",
    "                        count += 1\n",
    "\n",
    "            if len(B) > 0 and count == len(B[i][j].tuples):\n",
    "                # If all of the tuples satisfies the condition then mark the pixel as a foreground\n",
    "                F[i][j] = 1\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMBS4(video):\n",
    "    P = 5  # The sampling period\n",
    "    N = 15 # The number background samples to analyse\n",
    "    D = 2  # The minimal number D of occurrences to consider a tuple ⟨r,g,b,d ≥ D⟩ as a significant background value\n",
    "    A = 5  # The association threshold A for assigning a pixel to an existing tuple\n",
    "    t = 0  # Current time\n",
    "    n = 0  # According to a sampling period P, the current frame I is added to L, thus becoming a background sample Sn, 1 ≤ n ≤ N\n",
    "    ts = 0 # The timestamp of the last processed background sample\n",
    "    B = []\n",
    "\n",
    "    if video.isOpened():\n",
    "        ratio = WIDTH / video.get(3)\n",
    "        global HEIGHT\n",
    "        HEIGHT = math.floor(video.get(4) * ratio)\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "        \n",
    "        # GAUSSIAN FILTER ----------------------------------------------------------------------------------------\n",
    "        frame = cv2.GaussianBlur(frame, (13, 13), 0)\n",
    "\n",
    "        resizedFrame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "\n",
    "        frame = np.array(resizedFrame, dtype='int64')\n",
    "        if t - ts > P:\n",
    "            # During the sampling period, tuples are create or updated\n",
    "            B = registerBackground(n, frame, B, N, D, A)\n",
    "            ts = t\n",
    "            n += 1\n",
    "            if n == N:\n",
    "                n = 0\n",
    "\n",
    "        t += 1\n",
    "        # SUPPRESS SHADOWS -----------------------------------------------------------------------------------------\n",
    "        foreground = suppressShadows(frame, B)\n",
    "        visualFrame = getForegroundVisualFrame(foreground)\n",
    "        \n",
    "        # MORPHOLOGICAL OPERATORS -----------------------------------------------------------------------------------\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        \n",
    "        cv2.imshow(\"Foreground\", visualFrame)\n",
    "\n",
    "        cv2.imshow(\"Image\", resizedFrame)\n",
    "        key = cv2.waitKey(100)\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision With MOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMBS5(video):\n",
    "    P = 5  # The sampling period\n",
    "    N = 15 # The number background samples to analyse\n",
    "    D = 2  # The minimal number D of occurrences to consider a tuple ⟨r,g,b,d ≥ D⟩ as a significant background value\n",
    "    A = 5  # The association threshold A for assigning a pixel to an existing tuple\n",
    "    t = 0  # Current time\n",
    "    n = 0  # According to a sampling period P, the current frame I is added to L, thus becoming a background sample Sn, 1 ≤ n ≤ N\n",
    "    ts = 0 # The timestamp of the last processed background sample\n",
    "    B = []\n",
    "\n",
    "    if video.isOpened():\n",
    "        ratio = WIDTH / video.get(3)\n",
    "        global HEIGHT\n",
    "        HEIGHT = math.floor(video.get(4) * ratio)\n",
    "        \n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while True:\n",
    "        check, frame = video.read()\n",
    "        \n",
    "        # GAUSSIAN FILTER ----------------------------------------------------------------------------------------\n",
    "        frame = cv2.GaussianBlur(frame, (13, 13), 0)\n",
    "\n",
    "        resizedFrame = cv2.resize(frame, (WIDTH, HEIGHT))\n",
    "\n",
    "        frame = np.array(resizedFrame, dtype='int64')\n",
    "        if t - ts > P:\n",
    "            # During the sampling period, tuples are create or updated\n",
    "            B = registerBackground(n, frame, B, N, D, A)\n",
    "            ts = t\n",
    "            n += 1\n",
    "            if n == N:\n",
    "                n = 0\n",
    "\n",
    "        t += 1\n",
    "        # SUPPRESS SHADOWS -----------------------------------------------------------------------------------------\n",
    "        foreground = suppressShadows(frame, B)\n",
    "        visualFrame = getForegroundVisualFrame(foreground)\n",
    "        \n",
    "        # MORPHOLOGICAL OPERATORS -----------------------------------------------------------------------------------\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        visualFrame = cv2.morphologyEx(visualFrame, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "        \n",
    "        cv2.imshow(\"IMBS\", visualFrame)\n",
    "\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        cv2.imshow('MOG', fgmask)\n",
    "        key = cv2.waitKey(100)\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('video2.avi')\n",
    "IMBS5(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
